{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from scipy.stats import norm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "from sklearn.linear_model import Ridge,Lasso\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn import linear_model\n",
    "from sklearn.metrics import r2_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train=pd.read_csv('data/train.csv')\n",
    "df_test=pd.read_csv('data/test.csv') \n",
    "df_test['SalePrice'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_list = ['Alley','Heating','HeatingQC','CentralAir','Electrical','BsmtQual','BsmtCond','SaleType','SaleCondition',\\\n",
    "           'PavedDrive']\n",
    "#str_list = []\n",
    "num_cat = ['Fireplaces', 'TotRmsAbvGrd', 'FullBath', 'GarageCars', 'OverallQual']\n",
    "#num_cat = []\n",
    "num_list = ['MasVnrArea', 'GarageYrBlt', 'YearRemodAdd', 'YearBuilt', '1stFlrSF', 'TotalBsmtSF', 'GarageArea', 'GrLivArea']\n",
    "all_list = ['Id'] + str_list + num_cat + num_list + ['SalePrice']\n",
    "df_total = pd.concat([df_train,df_test],axis=0)\n",
    "\n",
    "#print(df_total.shape)\n",
    "df_use = df_total[all_list]\n",
    "#print(df_use.shape)\n",
    "#print(df_use.tail())\n",
    "#print(df_train[str_list])\n",
    "# str_list = ['MSZoning', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', \\\n",
    "#             'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2', 'BldgType', \\\n",
    "#             'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrType', \\\n",
    "#             'ExterQual', 'ExterCond', 'Foundation', 'BsmtQual', 'BsmtCond', 'BsmtExposure', \\\n",
    "#             'BsmtFinType1', 'BsmtFinType2', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', \\\n",
    "#             'KitchenQual', 'Functional', 'FireplaceQu', 'GarageType', 'GarageFinish', 'GarageQual', \\\n",
    "#             'GarageCond', 'PavedDrive', 'PoolQC', 'Fence', 'MiscFeature', 'SaleType', 'SaleCondition']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import TransformerMixin\n",
    "class DataFrameImputer(TransformerMixin):\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Impute missing values.\n",
    "\n",
    "        Columns of dtype object are imputed with the most frequent value \n",
    "        in column.\n",
    "\n",
    "        Columns of other types are imputed with mean of column.\n",
    "\n",
    "        \"\"\"\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        self.fill = pd.Series([X[c].value_counts().index[0]\n",
    "            if X[c].dtype == np.dtype('O') else X[c].mean() for c in X],\n",
    "            index=X.columns)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X, y=None):\n",
    "        return X.fillna(self.fill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fill nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "df_remove_nan = DataFrameImputer().fit_transform(df_use)\n",
    "print(df_remove_nan.isnull().sum().max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.utils import check_array\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from scipy import sparse\n",
    "\n",
    "class CategoricalEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "\n",
    "    def __init__(self, encoding='onehot', categories='auto', dtype=np.float64,\n",
    "                 handle_unknown='error'):\n",
    "        self.encoding = encoding\n",
    "        self.categories = categories\n",
    "        self.dtype = dtype\n",
    "        self.handle_unknown = handle_unknown\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "\n",
    "        if self.encoding not in ['onehot', 'onehot-dense', 'ordinal']:\n",
    "            template = (\"encoding should be either 'onehot', 'onehot-dense' \"\n",
    "                        \"or 'ordinal', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.handle_unknown not in ['error', 'ignore']:\n",
    "            template = (\"handle_unknown should be either 'error' or \"\n",
    "                        \"'ignore', got %s\")\n",
    "            raise ValueError(template % self.handle_unknown)\n",
    "\n",
    "        if self.encoding == 'ordinal' and self.handle_unknown == 'ignore':\n",
    "            raise ValueError(\"handle_unknown='ignore' is not supported for\"\n",
    "                             \" encoding='ordinal'\")\n",
    "\n",
    "        X = check_array(X, dtype=np.object, accept_sparse='csc', copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "\n",
    "        self._label_encoders_ = [LabelEncoder() for _ in range(n_features)]\n",
    "\n",
    "        for i in range(n_features):\n",
    "            le = self._label_encoders_[i]\n",
    "            Xi = X[:, i]\n",
    "            if self.categories == 'auto':\n",
    "                le.fit(Xi)\n",
    "            else:\n",
    "                valid_mask = np.in1d(Xi, self.categories[i])\n",
    "                if not np.all(valid_mask):\n",
    "                    if self.handle_unknown == 'error':\n",
    "                        diff = np.unique(Xi[~valid_mask])\n",
    "                        msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                               \" during fit\".format(diff, i))\n",
    "                        raise ValueError(msg)\n",
    "                le.classes_ = np.array(np.sort(self.categories[i]))\n",
    "\n",
    "        self.categories_ = [le.classes_ for le in self._label_encoders_]\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = check_array(X, accept_sparse='csc', dtype=np.object, copy=True)\n",
    "        n_samples, n_features = X.shape\n",
    "        X_int = np.zeros_like(X, dtype=np.int)\n",
    "        X_mask = np.ones_like(X, dtype=np.bool)\n",
    "\n",
    "        for i in range(n_features):\n",
    "            valid_mask = np.in1d(X[:, i], self.categories_[i])\n",
    "\n",
    "            if not np.all(valid_mask):\n",
    "                if self.handle_unknown == 'error':\n",
    "                    diff = np.unique(X[~valid_mask, i])\n",
    "                    msg = (\"Found unknown categories {0} in column {1}\"\n",
    "                           \" during transform\".format(diff, i))\n",
    "                    raise ValueError(msg)\n",
    "                else:\n",
    "                    X_mask[:, i] = valid_mask\n",
    "                    X[:, i][~valid_mask] = self.categories_[i][0]\n",
    "            X_int[:, i] = self._label_encoders_[i].transform(X[:, i])\n",
    "\n",
    "        if self.encoding == 'ordinal':\n",
    "            return X_int.astype(self.dtype, copy=False)\n",
    "\n",
    "        mask = X_mask.ravel()\n",
    "        n_values = [cats.shape[0] for cats in self.categories_]\n",
    "        n_values = np.array([0] + n_values)\n",
    "        indices = np.cumsum(n_values)\n",
    "\n",
    "        column_indices = (X_int + indices[:-1]).ravel()[mask]\n",
    "        row_indices = np.repeat(np.arange(n_samples, dtype=np.int32),\n",
    "                                n_features)[mask]\n",
    "        data = np.ones(n_samples * n_features)[mask]\n",
    "\n",
    "        out = sparse.csc_matrix((data, (row_indices, column_indices)),\n",
    "                                shape=(n_samples, indices[-1]),\n",
    "                                dtype=self.dtype).tocsr()\n",
    "        if self.encoding == 'onehot-dense':\n",
    "            return out.toarray()\n",
    "        else:\n",
    "            return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator,TransformerMixin\n",
    "#select columns and transit to array\n",
    "\n",
    "class DataFrameSelector(BaseEstimator,TransformerMixin):\n",
    "    def __init__(self,feature_names):\n",
    "        self.feature_names = feature_names\n",
    "    def fit(self,X,y=None):\n",
    "        return self\n",
    "    def transform(self,X):\n",
    "        return X[self.feature_names].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import Imputer   \n",
    "from sklearn.pipeline import FeatureUnion\n",
    "#CategoricalEncoder(encoding='onehot-dense')\n",
    "\n",
    "num_attribs = num_list\n",
    "num_pipeline = Pipeline([\n",
    "               ('selector',DataFrameSelector(num_attribs)),      \n",
    "#               ('std_scaler',StandardScaler()),\n",
    "              ])\n",
    "const_pipeline = Pipeline([\n",
    "               ('selector',DataFrameSelector(['Id','SalePrice'])),      \n",
    "              ])\n",
    "num_cat_attribs = str_list + num_cat\n",
    "num_obj_pipeline = Pipeline([\n",
    "                  ('selector',DataFrameSelector(num_cat_attribs)),\n",
    "                  ('cat_encoder',CategoricalEncoder(encoding='onehot-dense')),\n",
    "              ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pipeline = FeatureUnion(transformer_list=\n",
    "                             [\n",
    "                              ('const_pipeline',const_pipeline),\n",
    "                              ('num_pipeline',num_pipeline),\n",
    "                              \n",
    "                              ('num_obj_pipeline',num_obj_pipeline)\n",
    "                             ],\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Id Alley Heating HeatingQC CentralAir Electrical BsmtQual BsmtCond  \\\n",
      "0   1  Grvl    GasA        Ex          Y      SBrkr       Gd       TA   \n",
      "1   2  Grvl    GasA        Ex          Y      SBrkr       Gd       TA   \n",
      "2   3  Grvl    GasA        Ex          Y      SBrkr       Gd       TA   \n",
      "3   4  Grvl    GasA        Gd          Y      SBrkr       TA       Gd   \n",
      "4   5  Grvl    GasA        Ex          Y      SBrkr       Gd       TA   \n",
      "\n",
      "  SaleType SaleCondition    ...     OverallQual  MasVnrArea  GarageYrBlt  \\\n",
      "0       WD        Normal    ...               7       196.0       2003.0   \n",
      "1       WD        Normal    ...               6         0.0       1976.0   \n",
      "2       WD        Normal    ...               7       162.0       2001.0   \n",
      "3       WD       Abnorml    ...               7         0.0       1998.0   \n",
      "4       WD        Normal    ...               8       350.0       2000.0   \n",
      "\n",
      "   YearRemodAdd  YearBuilt  1stFlrSF  TotalBsmtSF  GarageArea  GrLivArea  \\\n",
      "0          2003       2003       856        856.0       548.0       1710   \n",
      "1          1976       1976      1262       1262.0       460.0       1262   \n",
      "2          2002       2001       920        920.0       608.0       1786   \n",
      "3          1970       1915       961        756.0       642.0       1717   \n",
      "4          2000       2000      1145       1145.0       836.0       2198   \n",
      "\n",
      "   SalePrice  \n",
      "0     208500  \n",
      "1     181500  \n",
      "2     223500  \n",
      "3     140000  \n",
      "4     250000  \n",
      "\n",
      "[5 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df_remove_nan.head())\n",
    "df_final = full_pipeline.fit_transform(df_remove_nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2919, 97)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.DataFrame(df_final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "      <th>94</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2899</th>\n",
       "      <td>2900.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>257.0</td>\n",
       "      <td>1975.000000</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1975.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>1128.0</td>\n",
       "      <td>528.0</td>\n",
       "      <td>1210.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2900</th>\n",
       "      <td>2901.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1958.000000</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1958.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>1632.0</td>\n",
       "      <td>518.0</td>\n",
       "      <td>1650.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2901</th>\n",
       "      <td>2902.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.000000</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>1381.0</td>\n",
       "      <td>470.0</td>\n",
       "      <td>1403.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2902</th>\n",
       "      <td>2903.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>198.0</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1728.0</td>\n",
       "      <td>714.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2903</th>\n",
       "      <td>2904.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>2005.000000</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>682.0</td>\n",
       "      <td>1838.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2904</th>\n",
       "      <td>2905.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1951.000000</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1951.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>270.0</td>\n",
       "      <td>1600.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>2906.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.0</td>\n",
       "      <td>1997.000000</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1997.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>1288.0</td>\n",
       "      <td>784.0</td>\n",
       "      <td>1368.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2906</th>\n",
       "      <td>2907.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1977.000000</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>616.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>1304.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2907</th>\n",
       "      <td>2908.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1968.000000</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>1968.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>864.0</td>\n",
       "      <td>288.0</td>\n",
       "      <td>874.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2908</th>\n",
       "      <td>2909.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>928.0</td>\n",
       "      <td>1652.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2909</th>\n",
       "      <td>2910.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978.113406</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>630.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2910</th>\n",
       "      <td>2911.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1972.000000</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>1972.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>253.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2911</th>\n",
       "      <td>2912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>194.0</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>336.0</td>\n",
       "      <td>1360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2912</th>\n",
       "      <td>2913.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2913</th>\n",
       "      <td>2914.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978.113406</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>2915.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978.113406</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>2916.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1970.000000</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>1970.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>546.0</td>\n",
       "      <td>286.0</td>\n",
       "      <td>1092.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>2917.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1960.000000</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1960.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1224.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2917</th>\n",
       "      <td>2918.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1978.113406</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>1992.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>912.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>2919.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>1993.000000</td>\n",
       "      <td>1994.0</td>\n",
       "      <td>1993.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>996.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 97 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0    1      2            3       4       5       6       7      8   \\\n",
       "2899  2900.0  0.0  257.0  1975.000000  1975.0  1975.0  1210.0  1128.0  528.0   \n",
       "2900  2901.0  0.0    0.0  1958.000000  1958.0  1958.0  1650.0  1632.0  518.0   \n",
       "2901  2902.0  0.0    0.0  2000.000000  2000.0  2000.0  1403.0  1381.0  470.0   \n",
       "2902  2903.0  0.0  198.0  2005.000000  2006.0  2005.0  1960.0  1728.0  714.0   \n",
       "2903  2904.0  0.0  382.0  2005.000000  2006.0  2005.0  1838.0  1838.0  682.0   \n",
       "2904  2905.0  0.0    0.0  1951.000000  1951.0  1951.0  1600.0     0.0  270.0   \n",
       "2905  2906.0  0.0  200.0  1997.000000  1997.0  1997.0  1368.0  1288.0  784.0   \n",
       "2906  2907.0  0.0    0.0  1977.000000  1977.0  1977.0   616.0   264.0  336.0   \n",
       "2907  2908.0  0.0    0.0  1968.000000  2003.0  1968.0   874.0   864.0  288.0   \n",
       "2908  2909.0  0.0    0.0  1970.000000  1970.0  1970.0  1652.0  1652.0  928.0   \n",
       "2909  2910.0  0.0    0.0  1978.113406  1970.0  1970.0   630.0   630.0    0.0   \n",
       "2910  2911.0  0.0    0.0  1972.000000  1972.0  1972.0   546.0   546.0  253.0   \n",
       "2911  2912.0  0.0  194.0  1969.000000  1979.0  1969.0  1360.0  1104.0  336.0   \n",
       "2912  2913.0  0.0    0.0  1970.000000  1970.0  1970.0   546.0   546.0  286.0   \n",
       "2913  2914.0  0.0    0.0  1978.113406  1970.0  1970.0   546.0   546.0    0.0   \n",
       "2914  2915.0  0.0    0.0  1978.113406  1970.0  1970.0   546.0   546.0    0.0   \n",
       "2915  2916.0  0.0    0.0  1970.000000  1970.0  1970.0   546.0   546.0  286.0   \n",
       "2916  2917.0  0.0    0.0  1960.000000  1996.0  1960.0  1224.0  1224.0  576.0   \n",
       "2917  2918.0  0.0    0.0  1978.113406  1992.0  1992.0   970.0   912.0    0.0   \n",
       "2918  2919.0  0.0   94.0  1993.000000  1994.0  1993.0   996.0   996.0  650.0   \n",
       "\n",
       "          9  ...    87   88   89   90   91   92   93   94   95   96  \n",
       "2899  1210.0 ...   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2900  1650.0 ...   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2901  1403.0 ...   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "2902  1960.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
       "2903  1838.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  \n",
       "2904  1600.0 ...   1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2905  1368.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "2906  1304.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2907   874.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2908  1652.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2909   630.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2910  1092.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2911  1360.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2912  1092.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2913  1092.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2914  1092.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2915  1092.0 ...   0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2916  1224.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2917   970.0 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2918  2000.0 ...   0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  \n",
       "\n",
       "[20 rows x 97 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.tail(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Id\n",
      "1460  1461.0\n",
      "1461  1462.0\n",
      "1462  1463.0\n",
      "1463  1464.0\n",
      "1464  1465.0\n",
      "         2       3       4       5       6       7      8       9    10   11  \\\n",
      "1460    0.0  1961.0  1961.0  1961.0   896.0   882.0  730.0   896.0  1.0  0.0   \n",
      "1461  108.0  1958.0  1958.0  1958.0  1329.0  1329.0  312.0  1329.0  1.0  0.0   \n",
      "1462    0.0  1997.0  1998.0  1997.0   928.0   928.0  482.0  1629.0  1.0  0.0   \n",
      "1463   20.0  1998.0  1998.0  1998.0   926.0   926.0  470.0  1604.0  1.0  0.0   \n",
      "1464    0.0  1992.0  1992.0  1992.0  1280.0  1280.0  506.0  1280.0  1.0  0.0   \n",
      "\n",
      "     ...    87   88   89   90   91   92   93   94   95   96  \n",
      "1460 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1461 ...   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
      "1462 ...   0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
      "1463 ...   0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
      "1464 ...   0.0  0.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  \n",
      "\n",
      "[5 rows x 95 columns]\n",
      "(2919, 97)\n",
      "(1460, 97)\n",
      "(1459, 95)\n",
      "df_final_test.shape (1459, 95) X_train_features.shape (1460, 95)\n",
      "0    12.247694\n",
      "1    12.109011\n",
      "2    12.317167\n",
      "3    11.849398\n",
      "4    12.429216\n",
      "Name: 1, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "df_final_train = df_final[df_final[1]>0]\n",
    "df_final_test = df_final[df_final[1]<0.1]\n",
    "\n",
    "Save2File=pd.DataFrame()\n",
    "Save2File['Id']=df_final_test[0]\n",
    "print(Save2File.head())\n",
    "\n",
    "df_final_test = df_final_test.drop(df_final_test.columns[0:2],axis=1)\n",
    "print(df_final_test.head())\n",
    "\n",
    "print(df_final.shape)\n",
    "print(df_final_train.shape)\n",
    "print(df_final_test.shape)\n",
    "X_train_features = df_final_train.drop(df_final_train.columns[0:2],axis=1)\n",
    "print('df_final_test.shape',df_final_test.shape,'X_train_features.shape',X_train_features.shape)\n",
    "#y_train_features = df_final_train[1]\n",
    "y_train_features = np.log(df_final_train[1])\n",
    "print(y_train_features[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(978, 95)\n"
     ]
    }
   ],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X_train_features,y_train_features,test_size=0.33)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1460, 97)\n",
      "(1459, 95)\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.20,degree=1, train data: r2_score=0.66\n",
      "epoch=1,alpha=0.20,degree=1, test data: r2_score=0.78\n",
      "Mean Square Error:  0.15711622003477826\n",
      "COME IN mean_squared_error 0.024685506598016858 degree best 1 alpha_best 0.2 score_train 0.04183755293759379\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.20,degree=1, train data: r2_score=0.67\n",
      "epoch=2,alpha=0.20,degree=1, test data: r2_score=0.75\n",
      "Mean Square Error:  0.16205508003130056\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.20,degree=1, train data: r2_score=0.68\n",
      "epoch=3,alpha=0.20,degree=1, test data: r2_score=0.65\n",
      "Mean Square Error:  0.19588723093348237\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.20,degree=1, train data: r2_score=0.79\n",
      "epoch=4,alpha=0.20,degree=1, test data: r2_score=0.63\n",
      "Mean Square Error:  0.253805837121665\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=5,alpha=0.20,degree=1, train data: r2_score=0.66\n",
      "epoch=5,alpha=0.20,degree=1, test data: r2_score=0.71\n",
      "Mean Square Error:  0.17446138168442735\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=6,alpha=0.20,degree=1, train data: r2_score=0.69\n",
      "epoch=6,alpha=0.20,degree=1, test data: r2_score=0.72\n",
      "Mean Square Error:  0.18673033205689452\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.20,degree=1, train data: r2_score=0.68\n",
      "epoch=7,alpha=0.20,degree=1, test data: r2_score=0.74\n",
      "Mean Square Error:  0.16935586223302498\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.20,degree=1, train data: r2_score=0.72\n",
      "epoch=8,alpha=0.20,degree=1, test data: r2_score=0.67\n",
      "Mean Square Error:  0.188922247856657\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.20,degree=1, train data: r2_score=0.66\n",
      "epoch=9,alpha=0.20,degree=1, test data: r2_score=0.70\n",
      "Mean Square Error:  0.1845506898740935\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.20,degree=1, train data: r2_score=0.68\n",
      "epoch=10,alpha=0.20,degree=1, test data: r2_score=0.73\n",
      "Mean Square Error:  0.1780953312810056\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.20,degree=2, train data: r2_score=0.90\n",
      "epoch=1,alpha=0.20,degree=2, test data: r2_score=0.82\n",
      "Mean Square Error:  0.15768867373053697\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.20,degree=2, train data: r2_score=0.91\n",
      "epoch=2,alpha=0.20,degree=2, test data: r2_score=0.79\n",
      "Mean Square Error:  0.16554753840168016\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.20,degree=2, train data: r2_score=0.89\n",
      "epoch=3,alpha=0.20,degree=2, test data: r2_score=0.83\n",
      "Mean Square Error:  0.1527033780066984\n",
      "COME IN mean_squared_error 0.02331832165465662 degree best 2 alpha_best 0.2 score_train 0.0149918230229579\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.20,degree=2, train data: r2_score=0.90\n",
      "epoch=4,alpha=0.20,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.15204772909422395\n",
      "COME IN mean_squared_error 0.02311851192271052 degree best 2 alpha_best 0.2 score_train 0.013842831082563564\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=5,alpha=0.20,degree=2, train data: r2_score=0.90\n",
      "epoch=5,alpha=0.20,degree=2, test data: r2_score=0.86\n",
      "Mean Square Error:  0.1482385136045794\n",
      "COME IN mean_squared_error 0.02197465691569507 degree best 2 alpha_best 0.2 score_train 0.014322050409700325\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=6,alpha=0.20,degree=2, train data: r2_score=0.90\n",
      "epoch=6,alpha=0.20,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.146380175907331\n",
      "COME IN mean_squared_error 0.021427155898661166 degree best 2 alpha_best 0.2 score_train 0.01455294097500882\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.20,degree=2, train data: r2_score=0.91\n",
      "epoch=7,alpha=0.20,degree=2, test data: r2_score=0.80\n",
      "Mean Square Error:  0.1589723219416111\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.20,degree=2, train data: r2_score=0.89\n",
      "epoch=8,alpha=0.20,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.15060149317650046\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.20,degree=2, train data: r2_score=0.90\n",
      "epoch=9,alpha=0.20,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.15133416634258853\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.20,degree=2, train data: r2_score=0.89\n",
      "epoch=10,alpha=0.20,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.14144219912744643\n",
      "COME IN mean_squared_error 0.020005895694008208 degree best 2 alpha_best 0.2 score_train 0.015409654863434395\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.40,degree=1, train data: r2_score=0.65\n",
      "epoch=1,alpha=0.40,degree=1, test data: r2_score=0.70\n",
      "Mean Square Error:  0.1748939625257163\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.40,degree=1, train data: r2_score=0.72\n",
      "epoch=2,alpha=0.40,degree=1, test data: r2_score=0.68\n",
      "Mean Square Error:  0.20823822696582245\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.40,degree=1, train data: r2_score=0.69\n",
      "epoch=3,alpha=0.40,degree=1, test data: r2_score=0.66\n",
      "Mean Square Error:  0.19751900792185276\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.40,degree=1, train data: r2_score=0.66\n",
      "epoch=4,alpha=0.40,degree=1, test data: r2_score=0.70\n",
      "Mean Square Error:  0.17164453888729012\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=5,alpha=0.40,degree=1, train data: r2_score=0.68\n",
      "epoch=5,alpha=0.40,degree=1, test data: r2_score=0.71\n",
      "Mean Square Error:  0.18351790749563737\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=6,alpha=0.40,degree=1, train data: r2_score=0.77\n",
      "epoch=6,alpha=0.40,degree=1, test data: r2_score=0.64\n",
      "Mean Square Error:  0.2443861748449446\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.40,degree=1, train data: r2_score=0.66\n",
      "epoch=7,alpha=0.40,degree=1, test data: r2_score=0.63\n",
      "Mean Square Error:  0.19438589207175191\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.40,degree=1, train data: r2_score=0.66\n",
      "epoch=8,alpha=0.40,degree=1, test data: r2_score=0.66\n",
      "Mean Square Error:  0.18469518652063072\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.40,degree=1, train data: r2_score=0.65\n",
      "epoch=9,alpha=0.40,degree=1, test data: r2_score=0.72\n",
      "Mean Square Error:  0.17940533244195628\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.40,degree=1, train data: r2_score=0.75\n",
      "epoch=10,alpha=0.40,degree=1, test data: r2_score=0.65\n",
      "Mean Square Error:  0.21990461868656935\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=1,alpha=0.40,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.1390436338326101\n",
      "COME IN mean_squared_error 0.01933313210937695 degree best 2 alpha_best 0.4 score_train 0.016559408605607485\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=2,alpha=0.40,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.15464542283023333\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=3,alpha=0.40,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.1436378619469207\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=4,alpha=0.40,degree=2, test data: r2_score=0.81\n",
      "Mean Square Error:  0.16783696632437217\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=5,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=5,alpha=0.40,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.14170724086432873\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=6,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=6,alpha=0.40,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.15018695543961355\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.40,degree=2, train data: r2_score=0.90\n",
      "epoch=7,alpha=0.40,degree=2, test data: r2_score=0.82\n",
      "Mean Square Error:  0.16150269425875022\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=8,alpha=0.40,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.1481502859505911\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=9,alpha=0.40,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.14886919008073818\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.40,degree=2, train data: r2_score=0.89\n",
      "epoch=10,alpha=0.40,degree=2, test data: r2_score=0.82\n",
      "Mean Square Error:  0.1553557729719971\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.60,degree=1, train data: r2_score=0.66\n",
      "epoch=1,alpha=0.60,degree=1, test data: r2_score=0.71\n",
      "Mean Square Error:  0.16457640634490062\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.60,degree=1, train data: r2_score=0.64\n",
      "epoch=2,alpha=0.60,degree=1, test data: r2_score=0.68\n",
      "Mean Square Error:  0.17819194543542985\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.60,degree=1, train data: r2_score=0.73\n",
      "epoch=3,alpha=0.60,degree=1, test data: r2_score=0.65\n",
      "Mean Square Error:  0.22722111722622426\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.60,degree=1, train data: r2_score=0.76\n",
      "epoch=4,alpha=0.60,degree=1, test data: r2_score=0.59\n",
      "Mean Square Error:  0.24534424742174332\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=5,alpha=0.60,degree=1, train data: r2_score=0.64\n",
      "epoch=5,alpha=0.60,degree=1, test data: r2_score=0.71\n",
      "Mean Square Error:  0.17558041105890068\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=6,alpha=0.60,degree=1, train data: r2_score=0.63\n",
      "epoch=6,alpha=0.60,degree=1, test data: r2_score=0.73\n",
      "Mean Square Error:  0.17269797644663817\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.60,degree=1, train data: r2_score=0.75\n",
      "epoch=7,alpha=0.60,degree=1, test data: r2_score=0.60\n",
      "Mean Square Error:  0.22755092425431656\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.60,degree=1, train data: r2_score=0.74\n",
      "epoch=8,alpha=0.60,degree=1, test data: r2_score=0.62\n",
      "Mean Square Error:  0.21711092004523178\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.60,degree=1, train data: r2_score=0.64\n",
      "epoch=9,alpha=0.60,degree=1, test data: r2_score=0.69\n",
      "Mean Square Error:  0.18002705635508248\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.60,degree=1, train data: r2_score=0.68\n",
      "epoch=10,alpha=0.60,degree=1, test data: r2_score=0.66\n",
      "Mean Square Error:  0.1950745031602325\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.60,degree=2, train data: r2_score=0.89\n",
      "epoch=1,alpha=0.60,degree=2, test data: r2_score=0.76\n",
      "Mean Square Error:  0.18782409519094664\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.60,degree=2, train data: r2_score=0.88\n",
      "epoch=2,alpha=0.60,degree=2, test data: r2_score=0.87\n",
      "Mean Square Error:  0.1438827154803132\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.60,degree=2, train data: r2_score=0.88\n",
      "epoch=3,alpha=0.60,degree=2, test data: r2_score=0.86\n",
      "Mean Square Error:  0.1413534766536717\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.60,degree=2, train data: r2_score=0.88\n",
      "epoch=4,alpha=0.60,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.15850043690473392\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=5,alpha=0.60,degree=2, train data: r2_score=0.88\n",
      "epoch=5,alpha=0.60,degree=2, test data: r2_score=0.86\n",
      "Mean Square Error:  0.13977122281572266\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=6,alpha=0.60,degree=2, train data: r2_score=0.88\n",
      "epoch=6,alpha=0.60,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.1488628300434145\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.60,degree=2, train data: r2_score=0.89\n",
      "epoch=7,alpha=0.60,degree=2, test data: r2_score=0.80\n",
      "Mean Square Error:  0.16902156060100346\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.60,degree=2, train data: r2_score=0.88\n",
      "epoch=8,alpha=0.60,degree=2, test data: r2_score=0.83\n",
      "Mean Square Error:  0.15218663142413558\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.60,degree=2, train data: r2_score=0.89\n",
      "epoch=9,alpha=0.60,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.14709792961086518\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.60,degree=2, train data: r2_score=0.89\n",
      "epoch=10,alpha=0.60,degree=2, test data: r2_score=0.79\n",
      "Mean Square Error:  0.1703932142341532\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.80,degree=1, train data: r2_score=0.67\n",
      "epoch=1,alpha=0.80,degree=1, test data: r2_score=0.66\n",
      "Mean Square Error:  0.19334321244146113\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.80,degree=1, train data: r2_score=0.64\n",
      "epoch=2,alpha=0.80,degree=1, test data: r2_score=0.67\n",
      "Mean Square Error:  0.17682959362867906\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.80,degree=1, train data: r2_score=0.63\n",
      "epoch=3,alpha=0.80,degree=1, test data: r2_score=0.69\n",
      "Mean Square Error:  0.16951067797923508\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.80,degree=1, train data: r2_score=0.59\n",
      "epoch=4,alpha=0.80,degree=1, test data: r2_score=0.73\n",
      "Mean Square Error:  0.16499583754221708\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=5,alpha=0.80,degree=1, train data: r2_score=0.67\n",
      "epoch=5,alpha=0.80,degree=1, test data: r2_score=0.65\n",
      "Mean Square Error:  0.1997246118059635\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=6,alpha=0.80,degree=1, train data: r2_score=0.63\n",
      "epoch=6,alpha=0.80,degree=1, test data: r2_score=0.68\n",
      "Mean Square Error:  0.17858425118782323\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.80,degree=1, train data: r2_score=0.62\n",
      "epoch=7,alpha=0.80,degree=1, test data: r2_score=0.71\n",
      "Mean Square Error:  0.1681907115688334\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.80,degree=1, train data: r2_score=0.78\n",
      "epoch=8,alpha=0.80,degree=1, test data: r2_score=0.59\n",
      "Mean Square Error:  0.25206425710710156\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.80,degree=1, train data: r2_score=0.71\n",
      "epoch=9,alpha=0.80,degree=1, test data: r2_score=0.62\n",
      "Mean Square Error:  0.2181221676827484\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.80,degree=1, train data: r2_score=0.63\n",
      "epoch=10,alpha=0.80,degree=1, test data: r2_score=0.66\n",
      "Mean Square Error:  0.18035452706030333\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=1,alpha=0.80,degree=2, train data: r2_score=0.88\n",
      "epoch=1,alpha=0.80,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.1480948575526695\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=2,alpha=0.80,degree=2, train data: r2_score=0.88\n",
      "epoch=2,alpha=0.80,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.1470312331332898\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=3,alpha=0.80,degree=2, train data: r2_score=0.88\n",
      "epoch=3,alpha=0.80,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.14339432054955698\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=4,alpha=0.80,degree=2, train data: r2_score=0.88\n",
      "epoch=4,alpha=0.80,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.15251628601134828\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=5,alpha=0.80,degree=2, train data: r2_score=0.87\n",
      "epoch=5,alpha=0.80,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.14024615360864875\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=6,alpha=0.80,degree=2, train data: r2_score=0.88\n",
      "epoch=6,alpha=0.80,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.1462057928562298\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=7,alpha=0.80,degree=2, train data: r2_score=0.87\n",
      "epoch=7,alpha=0.80,degree=2, test data: r2_score=0.86\n",
      "Mean Square Error:  0.13987847481060425\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=8,alpha=0.80,degree=2, train data: r2_score=0.88\n",
      "epoch=8,alpha=0.80,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.1492222298347164\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=9,alpha=0.80,degree=2, train data: r2_score=0.89\n",
      "epoch=9,alpha=0.80,degree=2, test data: r2_score=0.84\n",
      "Mean Square Error:  0.14630366469542985\n",
      "<class 'pandas.core.frame.DataFrame'> <class 'numpy.ndarray'>\n",
      "epoch=10,alpha=0.80,degree=2, train data: r2_score=0.88\n",
      "epoch=10,alpha=0.80,degree=2, test data: r2_score=0.85\n",
      "Mean Square Error:  0.15247323457836792\n",
      "The best case: epoch=10,alpha=0.40,degree=2, test_score=0.14, train_score=0.13\n"
     ]
    }
   ],
   "source": [
    "#degree=2\n",
    "#alpha=0.1\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(df_final_train.shape)\n",
    "print(df_final_test.shape)\n",
    "score_best =1\n",
    "score_train=0\n",
    "degree_best=0\n",
    "alpha_best =0\n",
    "for alpha in np.arange(0.2,1.0,0.2):\n",
    "    for degree in range(1,3):\n",
    "        for epoch in range(1,11):\n",
    "            Poly=PolynomialFeatures(degree=degree)\n",
    "            #df_sample=df_train_features[features_all_corr05].sample(frac=1).reset_index(drop=True)\n",
    "            X_train,X_test,y_train,y_test=train_test_split(X_train_features,y_train_features,test_size=0.33)\n",
    "            X_train_transform =Poly.fit_transform(X_train)\n",
    "            X_test_transform  =Poly.fit_transform(X_test) \n",
    "            \n",
    "            X_final_test  = Poly.fit_transform(df_final_test) # real testdata\n",
    "            \n",
    "            print(type(X_train),type(X_test_transform))\n",
    "            clf=linear_model.Lasso(alpha=alpha)\n",
    "            clf.fit(X_train_transform,y_train)\n",
    "            y_train_pred=clf.predict(X_train_transform)\n",
    "            y_test_pred=clf.predict(X_test_transform) \n",
    "            #print('X_test.shape',X_test.shape,'X_test_transform.shape',X_test_transform.shape,'y_test_pred.shape',y_test_pred.shape)\n",
    "            print('epoch={:d},alpha={:.2f},degree={:d}, train data: r2_score={:.2f}'\n",
    "                  .format(epoch,alpha,degree,r2_score(y_train_pred,y_train)))\n",
    "            print('epoch={:d},alpha={:.2f},degree={:d}, test data: r2_score={:.2f}'\n",
    "                  .format(epoch,alpha,degree,r2_score(y_test_pred,y_test)))\n",
    "            lin_mse = mean_squared_error(y_test,y_test_pred)\n",
    "            lin_rmse = np.sqrt(lin_mse)\n",
    "            print('Mean Square Error: ',lin_rmse)\n",
    "            if(mean_squared_error(y_test_pred,y_test) < score_best):\n",
    "                \n",
    "                score_best  = mean_squared_error(y_test_pred,y_test)\n",
    "                degree_best = degree\n",
    "                alpha_best  = alpha\n",
    "                score_train = mean_squared_error(y_train_pred,y_train)\n",
    "                print('COME IN mean_squared_error',score_best,'degree best',degree_best,'alpha_best',alpha_best,'score_train',score_train)\n",
    "                #print('df_final_test shape',df_final_test.shape,'X_test_transform shape',X_test_transform.shape)\n",
    "                #print('y_train_pred shape',y_train_pred.shape,'y_train shape',len(y_train))\n",
    "                \n",
    "                #print(X_test_transform[:6])\n",
    "                #print(df_final_test.head())\n",
    "                y_test_final = clf.predict(X_final_test) # prediction for real test data\n",
    "                Save2File['SalePrice']=y_test_final\n",
    "print(\"The best case: epoch={:d},alpha={:.2f},degree={:d}, test_score={:.2f}, train_score={:.2f}\"\n",
    "      .format(epoch,alpha_best,degree_best,np.sqrt(score_best),np.sqrt(score_train)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
